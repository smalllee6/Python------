涉及模块：urllib、BeautifulSoup、lxml、Scrapy、PdfMiner、Requests、Selenium、NLTK、Pillow、unittest、PySocks等
涉及数据库、网络服务器、HTTP协议、HTML语言、网络安全、图像处理、数据科学等内容


第一章 初见网络爬虫
网络连接
发送一串0和1比特值，这些构成一种信息：请求头和信息体，请求头包含当前本地路由器MAC地址和服务器的IP地址，消息体包含本地对服务器应用的请求
本地路由器收到0和1的比特值，把他们理解成一个数据包，从自己的MAC寄到服务器的IP地址。路由器盖上自己的Ip地址作为发件地址，通过互联网发出去
经过中介服务器，到达Alice的服务器
Alice服务器接收到数据包
Alice服务器读取数据包请求头里的目标端口（可以理解为数据包的房间号，IP地址就是街道地址），将它传递到对性的应用--网络服务器应用上
网络服务器应用从服务器粗砺崎街道一串数据，数据是这样的：这是一个GET请求，请求文件index.html
网络服务器找到对应的HTML，把它打包成一个新的数据包发送给Bob。

urllib 包括了从网络请求数据，处理cookie，甚至改变请求头和用户代理这些元数据的函数


pip install beautifulsoup4
from bs4 import BeautifulSoup

#示例
from urllib.request import urlopen
from bs4 import BeautifulSoup
from urllib.error import HTTPError
def getTitle(url):
	try:
		html=urlopen(url)
	except HTTPError:
		return None
	try:
		bsobj=BeautifulSoup(html.read())
		title=bsobj.body.h1
	except AttributeError as e:
		return None
	return title
title=getTitle('https://bbs.hupu.com/')
if title == None:
	print('Title could not be found')
else:
	print('{:^40}'.format('*'*20))
	print(title)
